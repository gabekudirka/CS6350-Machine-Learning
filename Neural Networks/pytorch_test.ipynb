{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class ReLuNN(nn.Module):\r\n",
    "  def __init__(self, input_size, width, depth):\r\n",
    "    super(ReLuNN, self).__init__()\r\n",
    "    self.input_size = input_size\r\n",
    "    self.width = width\r\n",
    "    self.depth = depth - 2\r\n",
    "    \r\n",
    "    self.input_layer = nn.Linear(self.input_size, self.width)\r\n",
    "    self.hidden_layer = nn.Linear(self.width, self.width)\r\n",
    "    self.output_layer = nn.Linear(self.width, 1)\r\n",
    "\r\n",
    "  def forward(self, x):\r\n",
    "    x = F.relu(self.input_layer(x))\r\n",
    "    for i in range(self.depth):\r\n",
    "      x = F.relu(self.hidden_layer(x))\r\n",
    "    x = self.output_layer(x)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "class TanHNN(nn.Module):\r\n",
    "  def __init__(self, input_size, width, depth):\r\n",
    "    super(TanHNN, self).__init__()\r\n",
    "    self.input_size = input_size\r\n",
    "    self.width = width\r\n",
    "    self.depth = depth - 2\r\n",
    "    \r\n",
    "    self.input_layer = nn.Linear(self.input_size, self.width)\r\n",
    "    self.hidden_layer = nn.Linear(self.width, self.width)\r\n",
    "    self.output_layer = nn.Linear(self.width, 1)\r\n",
    "\r\n",
    "  def forward(self, x):\r\n",
    "    x = F.tanh(self.input_layer(x))\r\n",
    "    for i in range(self.depth):\r\n",
    "      x = F.tanh(self.hidden_layer(x))\r\n",
    "    x = self.output_layer(x)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class BankNoteDataset(Dataset):\r\n",
    "    def __init__(self, filepath, attributes, label_col):\r\n",
    "        self.df = pd.read_csv(filepath, names=attributes)\r\n",
    "        self.df[label_col].iloc[self.df[label_col] == 0] = -1\r\n",
    "        self.X = self.df.loc[:, self.df.columns != label_col].to_numpy(dtype='float64')\r\n",
    "        self.y = self.df[label_col].to_numpy(dtype='float64')\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.X)\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32, device=DEVICE)\r\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32, device=DEVICE)\r\n",
    "        return X, y\r\n",
    "\r\n",
    "    def get_dims(self):\r\n",
    "        N, D = self.X.shape\r\n",
    "        return N, D"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def xavier(m):\r\n",
    "    if isinstance(m, nn.Linear):\r\n",
    "        nn.init.xavier_uniform_(m.weight)\r\n",
    "        m.bias.data.fill_(0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def he(m):\r\n",
    "    if isinstance(m, nn.Linear):\r\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\r\n",
    "        m.bias.data.fill_(0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def train(dataloader, model, optimizer, epochs=10):\r\n",
    "    avg_losses = []\r\n",
    "    loss_function = nn.MSELoss()\r\n",
    "    model = model.to(device=DEVICE)\r\n",
    "    for t in range(epochs):\r\n",
    "        losses = []\r\n",
    "        for i, (x, y) in enumerate(dataloader):\r\n",
    "            model.train()\r\n",
    "            pred = model(x)\r\n",
    "            loss = loss_function(torch.reshape(pred, y.shape), y)\r\n",
    "\r\n",
    "            optimizer.zero_grad()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "\r\n",
    "            losses.append(loss.item())\r\n",
    "        losses = np.asarray(losses).flatten()\r\n",
    "        avg_losses.append(losses.mean())\r\n",
    "    return avg_losses\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def test(dataloader, model):\r\n",
    "    loss_function = nn.MSELoss()\r\n",
    "    model = model.to(device=DEVICE)\r\n",
    "    incorrect_ctr = 0\r\n",
    "    avg_loss = 0\r\n",
    "    for i, (x, y) in enumerate(dataloader):\r\n",
    "        with torch.no_grad():\r\n",
    "            pred = model(x)\r\n",
    "            if torch.sign(pred) != y:\r\n",
    "                incorrect_ctr += 1\r\n",
    "            \r\n",
    "            loss = loss_function(torch.reshape(pred, y.shape), y)\r\n",
    "            avg_loss += loss\r\n",
    "            \r\n",
    "    return incorrect_ctr / len(dataloader), avg_loss / len(dataloader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "attributes = ['variance','skewness','curtosis','entropy','genuine']\r\n",
    "train_dataset = BankNoteDataset('../data/bank-note/train.csv', attributes, 'genuine')\r\n",
    "test_dataset = BankNoteDataset('../data/bank-note/test.csv', attributes, 'genuine')\r\n",
    "\r\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\r\n",
    "train_dataloader_test = DataLoader(train_dataset, batch_size=1, shuffle=True)\r\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "LEARNING_RATE = 0.001\r\n",
    "EPOCHS = 20\r\n",
    "N, D = train_dataset.get_dims()\r\n",
    "\r\n",
    "# model = ReLuNN(D, 5, 3)\r\n",
    "# optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
    "# losses = train(train_dataloader, model, optimizer, 50)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "widths = [5, 10, 25, 50, 100]\r\n",
    "depths = [3, 5, 9]\r\n",
    "losses = {}\r\n",
    "for depth in depths:\r\n",
    "    losses[depth] = {}\r\n",
    "    for width in widths:\r\n",
    "        model = ReLuNN(D, width, depth)\r\n",
    "        model.apply(he)\r\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
    "        losses[depth][width] = train(train_dataloader, model, optimizer, EPOCHS)\r\n",
    "\r\n",
    "        train_error, train_loss = test(train_dataloader_test, model)\r\n",
    "        test_error, test_loss = test(test_dataloader, model)\r\n",
    "\r\n",
    "        print('Model with depth = %d and width = %d:' % (depth, width))\r\n",
    "        print('Training error: %f - Test error %f' % (train_error, test_error))\r\n",
    "        print('Training loss: %f - Test loss %f' % (train_loss, test_loss))\r\n",
    "        print('')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model with depth = 3 and width = 5:\n",
      "Training error: 0.119266 - Test error 0.122000\n",
      "Training loss: 0.409450 - Test loss 0.416117\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "widths = [5, 10, 25, 50, 100]\r\n",
    "depths = [3, 5, 9]\r\n",
    "losses = {}\r\n",
    "for depth in depths:\r\n",
    "    losses[depth] = {}\r\n",
    "    for width in widths:\r\n",
    "        model = TanHNN(D, width, depth)\r\n",
    "        model.apply(xavier)\r\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
    "        losses[depth][width] = train(train_dataloader, model, optimizer, EPOCHS)\r\n",
    "        \r\n",
    "        train_error, train_loss = test(train_dataloader_test, model)\r\n",
    "        test_error, test_loss = test(test_dataloader, model)\r\n",
    "\r\n",
    "        print('Model with depth = %d and width = %d:' % (depth, width))\r\n",
    "        print('Training error: %f - Test error %f' % (train_error, test_error))\r\n",
    "        print('Training loss: %f - Test loss %f' % (train_loss, test_loss))\r\n",
    "        print('')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}