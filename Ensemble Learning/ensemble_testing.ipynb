{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\r\n",
    "sys.path.append('../')\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from decision_tree import DecisionTree as DecisionTreeAdaBoost\r\n",
    "from DecisionTree.decision_tree import DecisionTree as DecisionTreeOG\r\n",
    "from AdaBoost import AdaBoostTree\r\n",
    "from BaggedTrees import BaggedTrees, RandomForest"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def test_tree_accuracy(decision_tree, test_data):\r\n",
    "    preds = test_data.apply(lambda row : decision_tree.predict(row), axis=1)\r\n",
    "    diff = preds == test_data['label']\r\n",
    "    if (diff == True).all():\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        error_count = diff.value_counts()[False]\r\n",
    "        return error_count / len(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def process_data(df, attributes, replace_unknown=False, map_labels=True):\r\n",
    "    #If specified, replace all 'uknown' values with column majority\r\n",
    "    if replace_unknown:\r\n",
    "        for attribute in attributes:\r\n",
    "            if df[attribute].dtype.kind not in 'iufc':\r\n",
    "                most_common = 'unknown'\r\n",
    "                counts = df[attribute].value_counts()\r\n",
    "                if counts[[0]].index[0] == 'unknown' and len(counts) > 1:\r\n",
    "                    most_common = counts[[1]].index[0]\r\n",
    "                else:\r\n",
    "                    most_common = counts[[0]].index[0]\r\n",
    "                df[attribute][df[attribute] == 'unknown'] = most_common\r\n",
    "    \r\n",
    "    #Replace numerical columns with boolean values based on median threshold\r\n",
    "    for attribute in attributes:\r\n",
    "        if df[attribute].dtype.kind in 'iufc':\r\n",
    "            median = df[attribute].median()\r\n",
    "            binary_col = df[attribute] > median\r\n",
    "            df[attribute] = binary_col\r\n",
    "\r\n",
    "    if map_labels:\r\n",
    "        df.label[df.label == 'yes'] = 1\r\n",
    "        df.label[df.label == 'no'] = -1\r\n",
    "            \r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "attributes = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', \r\n",
    "'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\r\n",
    "\r\n",
    "df_train = pd.read_csv('../data/bank/train.csv', names=attributes + ['label'])\r\n",
    "df_test = pd.read_csv('../data/bank/test.csv', names=attributes + ['label'])\r\n",
    "\r\n",
    "df_train = process_data(df_train, attributes, replace_unknown=False)\r\n",
    "df_test = process_data(df_test, attributes, replace_unknown=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#Test AdaBoost\r\n",
    "training_errors = []\r\n",
    "test_errors = []\r\n",
    "T = np.arange(1, 505, 10)\r\n",
    "\r\n",
    "for t in T:\r\n",
    "    adaboost = AdaBoostTree(df_train, attributes)\r\n",
    "    adaboost.build_model(t)\r\n",
    "    training_errors.append(test_tree_accuracy(adaboost, df_train))\r\n",
    "    test_errors.append(test_tree_accuracy(adaboost, df_test))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Test Bagged Trees\r\n",
    "training_errors = []\r\n",
    "test_errors = []\r\n",
    "T = [1, 3, 5, 10, 15, 20, 30, 40, 50, 75, 100, 150, 200, 250, 300, 400, 500]\r\n",
    "\r\n",
    "for t in T:\r\n",
    "    bagged_trees = BaggedTrees(df_train, attributes)\r\n",
    "    bagged_trees.build_trees(t)\r\n",
    "    training_errors.append(test_tree_accuracy(bagged_trees, df_train))\r\n",
    "    test_errors.append(test_tree_accuracy(bagged_trees, df_test)) \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "textfile = open(\"training_errs_bt.txt\", \"w\")\r\n",
    "for element in training_errors:\r\n",
    "    textfile.write(str(element) + \", \")\r\n",
    "textfile.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "textfile = open(\"test_errs_bt.txt\", \"w\")\r\n",
    "for element in test_errors:\r\n",
    "    textfile.write(str(element) + \", \")\r\n",
    "textfile.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Bagged Trees bias/variance decomposition\r\n",
    "num_trees = 500\r\n",
    "num_samples = 1000\r\n",
    "bagged_predictors = []\r\n",
    "\r\n",
    "for i in range(100):\r\n",
    "    bagged_trees = BaggedTrees(df_train, attributes)\r\n",
    "    bagged_trees.build_trees(num_trees, num_samples)\r\n",
    "    bagged_predictors.append(bagged_trees)\r\n",
    "\r\n",
    "single_trees = []\r\n",
    "for predictor in bagged_predictors:\r\n",
    "    single_trees.append(predictor.trees)\r\n",
    "\r\n",
    "single_tree_preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Test Random Forest\r\n",
    "training_errors_rf = {}\r\n",
    "test_errors_rf = {}\r\n",
    "T = [1, 3, 5, 10, 15, 20, 30, 40, 50, 75, 100, 150, 200, 250, 300, 400, 500]\r\n",
    "subset_sizes = [2, 4, 6]\r\n",
    "\r\n",
    "for subset_size in subset_sizes:\r\n",
    "    training_errors_rf[subset_size] = []\r\n",
    "    test_errors_rf[subset_size] = []\r\n",
    "    for t in T:\r\n",
    "        random_forest = RandomForest(df_train, attributes)\r\n",
    "        random_forest.build_trees(t, subset_size)\r\n",
    "        training_errors_rf[subset_size].append(test_tree_accuracy(random_forest, df_train))\r\n",
    "        test_errors_rf[subset_size].append(test_tree_accuracy(random_forest, df_test))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "\r\n",
    "with open('training_errs_rf.txt', 'w') as convert_file:\r\n",
    "     convert_file.write(json.dumps(training_errors_rf))\r\n",
    "\r\n",
    "with open('test_errors_rf_rf.txt', 'w') as convert_file:\r\n",
    "     convert_file.write(json.dumps(test_errors_rf))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}