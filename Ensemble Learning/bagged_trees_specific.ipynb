{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from decision_tree import DecisionTree as DecisionTreeAdaBoost\r\n",
    "from decision_tree import DecisionTree\r\n",
    "from AdaBoost import AdaBoostTree\r\n",
    "from BaggedTrees import BaggedTrees, RandomForest"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def test_tree_accuracy(decision_tree, test_data):\r\n",
    "    preds = test_data.apply(lambda row : decision_tree.predict(row), axis=1)\r\n",
    "    diff = preds == test_data['label']\r\n",
    "    if (diff == True).all():\r\n",
    "        return 0\r\n",
    "    else:\r\n",
    "        error_count = diff.value_counts()[False]\r\n",
    "        return error_count / len(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def process_data(df, attributes, replace_unknown=False, map_labels=True):\r\n",
    "    #If specified, replace all 'uknown' values with column majority\r\n",
    "    if replace_unknown:\r\n",
    "        for attribute in attributes:\r\n",
    "            if df[attribute].dtype.kind not in 'iufc':\r\n",
    "                most_common = 'unknown'\r\n",
    "                counts = df[attribute].value_counts()\r\n",
    "                if counts[[0]].index[0] == 'unknown' and len(counts) > 1:\r\n",
    "                    most_common = counts[[1]].index[0]\r\n",
    "                else:\r\n",
    "                    most_common = counts[[0]].index[0]\r\n",
    "                df[attribute][df[attribute] == 'unknown'] = most_common\r\n",
    "    \r\n",
    "    #Replace numerical columns with boolean values based on median threshold\r\n",
    "    for attribute in attributes:\r\n",
    "        if df[attribute].dtype.kind in 'iufc':\r\n",
    "            median = df[attribute].median()\r\n",
    "            binary_col = df[attribute] > median\r\n",
    "            df[attribute] = binary_col\r\n",
    "\r\n",
    "    if map_labels:\r\n",
    "        df.label[df.label == 'yes'] = 1\r\n",
    "        df.label[df.label == 'no'] = -1\r\n",
    "            \r\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "attributes = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', \r\n",
    "'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\r\n",
    "\r\n",
    "df_train = pd.read_csv('../data/bank/train.csv', names=attributes + ['label'])\r\n",
    "df_test = pd.read_csv('../data/bank/test.csv', names=attributes + ['label'])\r\n",
    "\r\n",
    "df_train = process_data(df_train, attributes, replace_unknown=False)\r\n",
    "df_test = process_data(df_test, attributes, replace_unknown=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Bagged Trees bias/variance decomposition\r\n",
    "num_trees = 100\r\n",
    "num_samples = 500\r\n",
    "bagged_predictors = []\r\n",
    "\r\n",
    "for i in range(3):\r\n",
    "    bagged_trees = BaggedTrees(df_train, attributes, df_train)\r\n",
    "    bagged_trees.build_trees(num_trees, num_samples)\r\n",
    "    bagged_predictors.append(bagged_trees)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "single_trees = [predictor.trees[0] for predictor in bagged_predictors]\r\n",
    "single_tree_biases = []\r\n",
    "single_tree_variances = []\r\n",
    "ctr = 0\r\n",
    "for idx, row in df_test.iterrows():\r\n",
    "    preds = []\r\n",
    "    for tree in single_trees:\r\n",
    "        try:\r\n",
    "            pred = tree.predict(row)\r\n",
    "        except:\r\n",
    "            ctr+=1\r\n",
    "            continue\r\n",
    "        preds.append(pred)\r\n",
    "    preds = np.asarray(preds)\r\n",
    "    avg_pred = np.mean(preds)\r\n",
    "    bias = (avg_pred - row['label'])**2\r\n",
    "    single_tree_biases.append(bias)\r\n",
    "    var = np.var(preds)\r\n",
    "    single_tree_variances.append(var)\r\n",
    "single_tree_bias = sum(single_tree_biases) / len(single_tree_biases)\r\n",
    "single_tree_var = sum(single_tree_variances) / len(single_tree_variances)\r\n",
    "single_tree_squared_err = single_tree_bias + single_tree_var\r\n",
    "print(ctr)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "bagged_tree_biases = []\r\n",
    "bagged_tree_variances = []\r\n",
    "ctr = 0\r\n",
    "for idx, row in df_test.iterrows():\r\n",
    "    preds = []\r\n",
    "    for predictor in bagged_predictors:\r\n",
    "        try:\r\n",
    "            pred = predictor.predict(row)\r\n",
    "        except:\r\n",
    "            ctr+=1\r\n",
    "            continue\r\n",
    "        preds.append(pred)\r\n",
    "    preds = np.asarray(preds)\r\n",
    "    avg_pred = np.mean(preds)\r\n",
    "    bias = (avg_pred - row['label'])**2\r\n",
    "    bagged_tree_biases.append(bias)\r\n",
    "    var = np.var(preds)\r\n",
    "    bagged_tree_variances.append(var)\r\n",
    "print(ctr)\r\n",
    "bagged_trees_bias = sum(bagged_tree_biases) / len(bagged_tree_biases)\r\n",
    "bagged_trees_var = sum(bagged_tree_variances) / len(bagged_tree_variances)\r\n",
    "bagged_trees_squared_err = bagged_trees_bias + bagged_trees_var"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print('Single Trees Bias: %f' % single_tree_bias)\r\n",
    "print('Single Trees Variance: %f' % single_tree_var)\r\n",
    "print('Single Trees Estimated Squared Error: %f' % single_tree_squared_err)\r\n",
    "\r\n",
    "print('Bagged Trees Bias: %f' % bagged_trees_bias)\r\n",
    "print('Bagged Trees Variance: %f' % bagged_trees_var)\r\n",
    "print('Bagged Trees Estimated Squared Error: %f' % bagged_trees_squared_err)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Single Trees Bias: 0.462400\n",
      "Single Trees Variance: 0.274133\n",
      "Single Trees Estimated Squared Error: 0.736533\n",
      "Bagged Trees Bias: 0.430844\n",
      "Bagged Trees Variance: 0.144356\n",
      "Bagged Trees Estimated Squared Error: 0.575200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bagged_tree_biases = np.asarray(bagged_tree_biases)\r\n",
    "bagged_tree_variances = np.asarray(bagged_tree_variances)\r\n",
    "\r\n",
    "bagged_tree_biases = bagged_tree_biases[~np.isnan(bagged_tree_biases)]\r\n",
    "bagged_tree_variances = bagged_tree_variances[~np.isnan(bagged_tree_variances)]\r\n",
    "\r\n",
    "bagged_trees_bias = sum(bagged_tree_biases) / len(bagged_tree_biases)\r\n",
    "bagged_trees_var = sum(bagged_tree_variances) / len(bagged_tree_variances)\r\n",
    "bagged_trees_squared_err = bagged_trees_bias + bagged_trees_var"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}